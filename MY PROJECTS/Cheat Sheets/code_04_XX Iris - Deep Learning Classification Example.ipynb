{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9cc808",
   "metadata": {},
   "source": [
    "# Deep Learning Example - Iris \n",
    "\n",
    "This examples demonstrates the core deep learning model building concepts using the Keras library. The Iris flower dataset is used to build the model and perform classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141cfab",
   "metadata": {},
   "source": [
    "### 5.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17aae7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: tensorflow in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (0.14.1)\n",
      "Requirement already satisfied: clang~=5.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (1.41.0)\n",
      "Requirement already satisfied: keras~=2.6 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorflow) (3.18.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: sklearn in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from sklearn) (1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (3.4.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from matplotlib) (8.3.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from matplotlib) (1.19.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from matplotlib) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from matplotlib) (2.4.7)\r\n",
      "Requirement already satisfied: six in /Users/linkedin/opt/anaconda3/envs/deeplearning/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "#Install related libraries for the course. \n",
    "#This is a common requirement for all other exampels too\n",
    "\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install sklearn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabf059",
   "metadata": {},
   "source": [
    "### 4.2. Prepare Input Data for Deep Learning\n",
    "\n",
    "Perform the following steps for preparing data\n",
    "\n",
    "1. Load data into a pandas dataframe\n",
    "2. Convert the dataframe to a numpy array\n",
    "3. Scale the feature dataset\n",
    "4. Use one-hot-encoding for the target variable\n",
    "5. Split into training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db4bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Data :\n",
      "------------------------------------\n",
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "Features before scaling :\n",
      "------------------------------------\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "Target before scaling :\n",
      "------------------------------------\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Features after scaling :\n",
      "------------------------------------\n",
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n",
      "\n",
      "Target after one-hot-encoding :\n",
      "------------------------------------\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "Train Test Dimensions:\n",
      "------------------------------------\n",
      "(135, 4) (135, 3) (15, 4) (15, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Load Data and review content\n",
    "iris_data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(iris_data.head())\n",
    "\n",
    "#Use a Label encoder to convert String to numeric values \n",
    "#for the target variable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris_data['Species'] = label_encoder.fit_transform(\n",
    "                                iris_data['Species'])\n",
    "\n",
    "#Convert input to numpy array\n",
    "np_iris = iris_data.to_numpy()\n",
    "\n",
    "#Separate feature and target variables\n",
    "X_data = np_iris[:,0:4]\n",
    "Y_data=np_iris[:,4]\n",
    "\n",
    "print(\"\\nFeatures before scaling :\\n------------------------------------\")\n",
    "print(X_data[:5,:])\n",
    "print(\"\\nTarget before scaling :\\n------------------------------------\")\n",
    "print(Y_data[:5])\n",
    "\n",
    "#Create a scaler model that is fit on the input data.\n",
    "scaler = StandardScaler().fit(X_data)\n",
    "\n",
    "#Scale the numeric feature variables\n",
    "X_data = scaler.transform(X_data)\n",
    "\n",
    "#Convert target variable as a one-hot-encoding array\n",
    "Y_data = tf.keras.utils.to_categorical(Y_data,3)\n",
    "\n",
    "print(\"\\nFeatures after scaling :\\n------------------------------------\")\n",
    "print(X_data[:5,:])\n",
    "print(\"\\nTarget after one-hot-encoding :\\n------------------------------------\")\n",
    "print(Y_data[:5,:])\n",
    "\n",
    "#Split training and test data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split( X_data, Y_data, test_size=0.10)\n",
    "\n",
    "print(\"\\nTrain Test Dimensions:\\n------------------------------------\")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5fad2",
   "metadata": {},
   "source": [
    "### 4.3. Creating a Model\n",
    "\n",
    "Creating a model in Keras requires defining the following\n",
    "\n",
    "1. Number of hidden layers\n",
    "2. Number of nodes in each layer\n",
    "3. Activation functions\n",
    "4. Loss Function & Accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a0be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Hidden-Layer-1 (Dense)       (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "Hidden-Layer-2 (Dense)       (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Output-Layer (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-02 08:22:29.187893: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "#Number of classes in the target variable\n",
    "NB_CLASSES=3\n",
    "\n",
    "#Create a sequencial model in Keras\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Add the first hidden layer\n",
    "model.add(keras.layers.Dense(128,                    #Number of nodes\n",
    "                             input_shape=(4,),       #Number of input variables\n",
    "                              name='Hidden-Layer-1', #Logical name\n",
    "                              activation='relu'))    #activation function\n",
    "\n",
    "#Add a second hidden layer\n",
    "model.add(keras.layers.Dense(128,\n",
    "                              name='Hidden-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add an output layer with softmax activation\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='Output-Layer',\n",
    "                             activation='softmax'))\n",
    "\n",
    "#Compile the model with loss & metrics\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Print the model meta-data\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6677e",
   "metadata": {},
   "source": [
    "### 4.4. Training and evaluating the Model\n",
    "\n",
    "Training the model involves defining various training models and then perform \n",
    "forward and back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a9ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:\n",
      "------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-02 08:30:49.300887: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
  